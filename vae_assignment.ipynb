{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Autoencoder (VAE) with MNIST\n",
    "\n",
    "![alt text](http://www.fastforwardlabs.com/blog-images/miriam/imgs_code/vae.4.png \"VAE\")\n",
    "\n",
    "\n",
    "## What is VAE?\n",
    "VAE is a type of generative model that can be used to **a)** take in an image and generate a new image with some desired quality (e.g. of a different style), **b)** generate images after being trained on some input training set, and **c)** understand the \"latent\" (hidden) factors that cause variations in the images. There are two stages to a VAE, which I will elaborate below.\n",
    "\n",
    "## Encode Stage\n",
    "This stage takes a data input vector `x` with dimension `n_in`. For example, this could be a dimension 784 image of a digit. The goal of this stage is to find a lower-dimensional representation for the set of images in general that captures the major variations between images (like the fact that 1 doesn't have a loop but 6 has a loop). This means that the encode phase will try to map an image `x` to a vector `z_mean` in the \"latent\" space, which contains the important characteristics of `x` in an encoded fashion. As a simple example, if we choose `z_mean` to be a shape (2,) vector, then `z_mean[0]` may quantify how loopy the digit is, and `z_mean[1]` may quantify how slanted the digit is. Obviously `2` characteristics alone will not let us distinguish between all the characters, but if we choose `z_mean`'s dimension (call this `n_latent`) to be around `20` or so, we have no problem encoding the important distinguishing features between the digits.\n",
    "\n",
    "## Decoding Stage\n",
    "The decoder takes the \"latent\" output of the encoder (for now think assume the output is `z_mean`), and attempts output some `y` that is close to a given goal $\\hat{y}$. In this particular assignment, $\\hat y = x$, meaning that we want the decoder to recover the original input `x` back from the encoding. This entire encoding / decoding process is kinda similar to compression (into the latent space) and trying to recover the original input as well as possible.\n",
    "\n",
    "## Encoding Stage Revisited\n",
    "The above is most of the basic idea of a normal (non-variational) autoencoder. One issue with the above is overfitting, i.e. the encoder and decoder will work together to perfectly generate the input that it sees, but fails on some new images from the test set. In that case, the encoder and decoder functions would learn specific mappings from each input $x_i$ in the training set to their respective $z_i$ and back to the original $x_i$, but fail to capture the larger general patterns (e.g. what makes a `0` look like a `0`). To guard against this, the encoding stage is modified as described below.\n",
    "\n",
    "Instead of modeling the latent space as a single vector `z_mean`, we represent each `z_mean[i]` as the mean of a gaussian distribution, and we also generate a vector `z_std`, so that `z_std[i]` is the standard deviation of the same gaussian distribution. We end up with `n_latent` independent distributions, and the ith distribution is $\\mathcal{N}(z_{mean}[i], z_{std}[i])$. The combination of the distribution at each i results in $\\mathcal{N}(z_{mean}, z_{std})$, which is called a multivariate gaussian distribution and is a joint distribution of all the $\\mathcal{N}(z_{mean}[i], z_{std}[i])$. This means that the original `x` corresponds to a sample of this multivariate distribution. Instead of outputting `z`, the encoder will output $z = z_{mean} + \\epsilon * z_{sigma}$, where each element of $\\epsilon$ is sampled from $\\mathcal{N}(0, 1)$ (the normal distribution with mean 0 and standard deviation 1). This `z` represents another sample from $\\mathcal{N}(z_{mean}, z_{std})$, and this `z` rather than `z_mean` is what we feed to the decoder during training, and aim to generate something similar to the original input `x`.\n",
    "\n",
    "**Don't worry too much about understanding the math**, but hopefully the above didn't confuse you too much. I think the motivation for using a normal distributed output `z` as the output of the encoding stage rather than just using `z_mean` is so that we can group together inputs with slight variations between them. For example, instead of mapping a digit 5 tilted at $15^\\circ$ and a digit 5 tilted at $16^\\circ$ to two completely different `z_mean`'s, we can now treat them as samples of the distribution $\\mathcal{N}(z_{mean}, z_{std})$, which represents the same object but allows for some minor variations.\n",
    "\n",
    "However, you can check out https://arxiv.org/pdf/1312.6114.pdf or https://arxiv.org/pdf/1606.05908.pdf if you're interested in the math.\n",
    "\n",
    "## Training the VAE\n",
    "We will represent the encoder and decoder as neural networks, and apply a loss at the end of the decoder so we can use gradient descent to update the weights to minimize the loss. This loss will be a combination of **a)** a measure of how far the generated output `y` is from the expected output $\\hat y = x$ and **b)** a measure of how close the distribution of $z$ is to a standard Gaussian $\\mathcal{N}(0, 1)$ (although we could choose a different distribution here). In the picture below, the right side is how our neural network will be structured, and the left side is the what the right side approximates.\n",
    "\n",
    "![alt text](http://blog.qure.ai/assets/images/vae/Encoder_Decoder_VAE.png \"architecture\")\n",
    "\n",
    "## Building the VAE\n",
    "See inline comments below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-18T20:49:23.811285",
     "start_time": "2017-03-18T13:49:21.499102-07:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from mnist import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-19T03:05:33.428488",
     "start_time": "2017-03-18T20:05:24.860113-07:00"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    mndata = MNIST('data/')\n",
    "    X_train, labels_train = map(np.array, mndata.load_training())\n",
    "    X_test, labels_test = map(np.array, mndata.load_testing())\n",
    "    X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "    return X_train, labels_train, X_test, labels_test\n",
    "\n",
    "X_train, labels_train, X_test, labels_test = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-19T04:23:46.965327",
     "start_time": "2017-03-18T21:23:46.775177-07:00"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class VAE:\n",
    "    def __init__(self, n_in, n_latent, n_out, learning_rate=1e-3):\n",
    "        '''\n",
    "        Essentially we hook up one net for the encoder and one for the decoder.\n",
    "        \n",
    "        Encoder:\n",
    "        x is an input image. z_mean, z_log_std are predicted from the encoder \n",
    "        and is used to create z, along with epsilon (which is sampled from a \n",
    "        random normal distribution)\n",
    "            x -- (encoder neural network) -- z_mean ---- z = z_mean + epsilon * z_std\n",
    "                                          \\- z_log_std --/ /\n",
    "             sample random normal N(0, 1) -- epsilon -----/\n",
    "        \n",
    "        Your choices of variable will be:\n",
    "            size of latent space (dimension of z_mean and z_log_std) - just choose n_latent = 20 for now\n",
    "            structure of encoder: You can try \n",
    "                x (n_in) -> FC (n_in to 500) -> relu -> FC (500 to 300) -> relu -> FC (300 to n_latent) -> z_mean (n_latent)\n",
    "                                                                               \\-> FC (300 to n_latent) -> z_log_std (n_latent)\n",
    "            where FC = fully connected. You can replace ReLU with some other activation function too if you want.\n",
    "            For the FC layers, initialize the weights with Xavier initialization and the biases to 0.\n",
    "            Notice that we are predicting the log of the std with this network, so to get std, you need to use \n",
    "            tf.exp(). Use tf.random_normal to generate epsilon.\n",
    "            \n",
    "            TRY NOT TO HARD CODE THE LAYER SIZES (it's useful to make these parameters of the __init__ so you can\n",
    "            specify them when you initialize the network)\n",
    "        '''\n",
    "        self.n_z = n_z\n",
    "        self.x = tf.placeholder(tf.float32, shape=(None, n_in))\n",
    "        \n",
    "        self.z_mean = # tensorflow expression\n",
    "        z_log_sq_sigma = # tensorflow expression\n",
    "\n",
    "        eps = # use tf.random_normal()\n",
    "        self.z = \n",
    "        \n",
    "        \n",
    "        '''\n",
    "        Decoder:\n",
    "            here n_out = n_in since we're trying to recreate the input\n",
    "            z (n_latent) -> FC (n_z to 300) -> relu -> FC (300 to 500) -> relu -> FC (500 to n_out) -> tf.nn.sigmoid -> y\n",
    "        '''\n",
    "        self.y = # output of decoder\n",
    "        \n",
    "        '''\n",
    "        Loss:\n",
    "        decode loss is the sum of how much output pixels deviates from the input pixels, the expression is:\n",
    "            -sum_i (x[i] * log(1e-10 + y[i]) + (1 - x[i]) log(1e-10 + 1 - y[i])),   0 <= i < n_in\n",
    "        You should do this in a VECTORIZED fashion. i.e. calculate a vector v then use tf.reduce_sum(v, axis=1)\n",
    "        \n",
    "        latent loss is how far the z distribution deviates from a standard normal, the expression is:\n",
    "            -sum_j (1 + log(z_sigma^2) - z_mean^2 - z_sigma^2),   0 <= j < n_latent\n",
    "        again, do this with vectorization\n",
    "        '''\n",
    "        decode_loss = \n",
    "        latent_loss = \n",
    "        \n",
    "        # the total loss is the average of (decode_loss + latent_loss) over the entrie batch, so use tf.reduce_mean()\n",
    "        self.loss = #\n",
    "        \n",
    "        # Doesn't really matter which optimizer\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(self.loss)\n",
    "        \n",
    "        # create tensorflow session here\n",
    "        self.sess =\n",
    "        \n",
    "    def fit_batch(self, x):\n",
    "        '''\n",
    "        feeds in a shape (batch, n_in) x into the network and do backprop\n",
    "        ''' \n",
    "        _, loss = self.sess.run((self.optimizer, self.loss), feed_dict={self.x: x})\n",
    "        return loss\n",
    "    \n",
    "    def encode(self, x):\n",
    "        '''\n",
    "        feeds in a shape (batch, n_in) x into the network and ONLY calculate self.z_mean (encoder phase only)\n",
    "        DO NOT DO backprop (aka don't pass in self.optimizer into self.sess.run)\n",
    "        if you coded your network flexibly, you don't need batch to equal n_batch (the batch size during training)\n",
    "        Hint: use self.sess.run again like in fit_batch, but modify a little\n",
    "        '''\n",
    "        return # fill me in\n",
    "    \n",
    "    def decode(self):\n",
    "        '''\n",
    "        feeds in a shape (batch, n_latent) z into the network and ONLY calculate the output (decoder phase only)\n",
    "        DO NOT DO backprop\n",
    "        \n",
    "        Essentially this allows you to generate a digit by feeding in a normal distribution z with unit standard variation!\n",
    "        '''\n",
    "        return \n",
    "    \n",
    "    def reconstruct(self, x):\n",
    "        '''\n",
    "        feeds in a shape (batch, n_in) x into the network and calculate self.y\n",
    "        DO NOT DO backprop\n",
    "        '''\n",
    "        return \n",
    "    \n",
    "    def train(self, X, batch_size, epochs, display_step=5):\n",
    "        '''\n",
    "        You should understand this code and be able to write this if you need to\n",
    "        '''\n",
    "        X = np.random.permutation(X)\n",
    "        n_samples = len(X)\n",
    "        mean_losses = []\n",
    "        for epoch in range(epochs):\n",
    "            total_iter = n_samples // batch_size\n",
    "            total_loss = 0\n",
    "            for i in range(total_iter):\n",
    "                x = X[i * batch_size : (i + 1) * batch_size]\n",
    "                loss = self.fit_batch(x)\n",
    "                total_loss += loss\n",
    "            mean_loss = total_loss / total_iter\n",
    "            mean_losses.append(mean_loss)\n",
    "            if (epoch + 1) % display_step == 0:\n",
    "                print('epoch %s: loss=%.4f' % (epoch + 1, mean_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-19T04:26:34.894352",
     "start_time": "2017-03-18T21:24:14.264022-07:00"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vae = # initialize VAE\n",
    "vae.train(X_train, 100, 25) # train with batch_size of 100 and 25 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-18T21:35:37.404004",
     "start_time": "2017-03-18T14:35:37.394997-07:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def graph(x_pred, x_true):\n",
    "    '''\n",
    "    graphs one predicted and one original x side by side\n",
    "    '''\n",
    "    for i, x in enumerate([x_pred, x_true]):\n",
    "        # use plt.subplot to put two plots side by side. Look this up!\n",
    "        plt.subplot\n",
    "        # use plt.imshow on a reshaped x, try the arguments cmap='gray' to use grayscale and interpolation='nearest'\n",
    "        plt.imshow\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict a few images from the test and training set, do the output look realistic?\n",
    "vae.reconstruct()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Space Visualization\n",
    "We will look at the latent space to understand it a little better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# retrain a vae with n_latent = 2\n",
    "vae_2d =\n",
    "vae_2d.train(X_train, 100, 15)\n",
    "\n",
    "# get 1000 samples from X_train, use vae_2d.encode to encode them into 2D latent space\n",
    "# plot the encoded points with color equal to their label (digit value)\n",
    "plt.scatter(x, y, c=labels)\n",
    "plt.colorbar() # show the color bar\n",
    "plt.show()\n",
    "# you should be able to see clusters of points corresonding to each label in the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now we will try feed in z_mean in a systematic way and use vae.decode to visualize what each z_mean generates\n",
    "nx = ny = 20\n",
    "# generates 20 evenly spaced x_values and y_values for the z_mean\n",
    "x_values = np.linspace(-3, 3, nx)\n",
    "y_values = np.linspace(-3, 3, ny)\n",
    "\n",
    "canvas = np.zeros((28 * ny, 28 * nx)) # a grid that will contain 20 x 20 digit images\n",
    "for i, yi in enumerate(x_values):\n",
    "    for j, xi in enumerate(y_values):\n",
    "        z_mean = np.array([[xi, yi]])\n",
    "        # decode z_mean and add the result to the canvas\n",
    "plt.imshow(canvas, cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
